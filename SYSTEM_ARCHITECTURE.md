# Mangwale Voice System - Enhanced Architecture

## ğŸ¯ How Your System Works Now

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER SPEAKS INTO DEVICE                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚ Audio Stream
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   VOICE GATEWAY (Mercury:7100)                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  WebSocket Connection + Voice Activity Detection (VAD)              â”‚   â”‚
â”‚  â”‚  â€¢ Detects when user starts/stops speaking                          â”‚   â”‚
â”‚  â”‚  â€¢ Buffers audio chunks                                             â”‚   â”‚
â”‚  â”‚  â€¢ Manages session state                                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚ Complete Audio
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ASR (Speech-to-Text) FALLBACK CHAIN                      â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ 1. LOCAL  â”‚ â”€â”€â–¶ â”‚ 2. DEEP-  â”‚ â”€â”€â–¶ â”‚ 3. GOOGLE â”‚ â”€â”€â–¶ â”‚ 4. AZURE  â”‚       â”‚
â”‚  â”‚ Whisper   â”‚     â”‚   GRAM    â”‚     â”‚   Cloud   â”‚     â”‚  Speech   â”‚       â”‚
â”‚  â”‚ (Mercury) â”‚     â”‚ Nova-2 âœ… â”‚     â”‚  (empty)  â”‚     â”‚  (empty)  â”‚       â”‚
â”‚  â”‚ FREE      â”‚     â”‚ ~$0.004/m â”‚     â”‚           â”‚     â”‚           â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚       â”‚                 â”‚                                                   â”‚
â”‚       â”‚ Latency: ~2s    â”‚ Latency: ~200ms                                   â”‚
â”‚       â”‚ Hindi: â˜…â˜…â˜…â˜…â˜…    â”‚ Hindi: â˜…â˜…â˜…â˜…â˜†                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚ Text
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    JUPITER (Main AI Server)                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Mangwale AI Service â†’ vLLM (Qwen 2.5 7B) â†’ Response Text           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚ Response Text
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TTS (Text-to-Speech) FALLBACK CHAIN                      â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ 1. LOCAL  â”‚ â”€â”€â–¶ â”‚ 2. ELEVEN â”‚ â”€â”€â–¶ â”‚ 3. DEEP-  â”‚ â”€â”€â–¶ â”‚ 4. GOOGLE â”‚       â”‚
â”‚  â”‚ XTTS v2   â”‚     â”‚   LABS    â”‚     â”‚   GRAM    â”‚     â”‚   Cloud   â”‚       â”‚
â”‚  â”‚ (Mercury) â”‚     â”‚ Flash âœ…  â”‚     â”‚ Aura âœ…   â”‚     â”‚  (empty)  â”‚       â”‚
â”‚  â”‚ FREE      â”‚     â”‚ ~75ms lat â”‚     â”‚ ~200ms    â”‚     â”‚           â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚       â”‚                 â”‚                                                   â”‚
â”‚       â”‚ Latency: ~3s    â”‚ Latency: ~75ms                                    â”‚
â”‚       â”‚ Hindi: â˜…â˜…â˜…â˜…â˜†    â”‚ Hindi: â˜…â˜…â˜…â˜†â˜†                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚ Audio
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER HEARS RESPONSE                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ… Current Capabilities

| Feature | Status | Provider |
|---------|--------|----------|
| Local ASR (Whisper Large-v3) | âœ… Active | Mercury GPU |
| Local TTS (XTTS v2) | âœ… Active | Mercury GPU |
| Cloud ASR Fallback (Deepgram) | âœ… Active | API Key Set |
| Cloud TTS Fallback (ElevenLabs) | âœ… Active | API Key Set |
| Voice Activity Detection | âœ… Active | Built-in |
| WebSocket Streaming | âœ… Active | Port 7100 |
| REST API | âœ… Active | Port 7101 |

## ğŸš€ Better Strategy: What You Should Do

### Phase 1: Optimize Current Stack (This Week)

#### 1.1 Switch to Faster-Whisper (4x Speed Boost)
Replace your current Whisper with **Faster-Whisper** for massive speed improvement.

**Before:** ~3 seconds for 10s audio
**After:** ~0.8 seconds for 10s audio

```bash
# Update ASR container to use faster-whisper
# In your ASR Dockerfile, replace:
# pip install openai-whisper
# With:
pip install faster-whisper
```

**Benchmark (13 min audio on RTX 3070):**
| Implementation | Time | Memory |
|---------------|------|--------|
| openai/whisper | 2m23s | 4.7GB |
| faster-whisper | 59s | 2.9GB |
| faster-whisper (batch) | 17s | 6GB |

#### 1.2 Use Whisper Turbo Model
New `large-v3-turbo` is 8x faster than large-v3 with similar accuracy:

```python
from faster_whisper import WhisperModel

# Instead of "large-v3", use "turbo"
model = WhisperModel("turbo", device="cuda", compute_type="float16")
segments, info = model.transcribe("audio.wav", 
    language="hi",
    vad_filter=True,  # Built-in Silero VAD
    beam_size=5
)
```

### Phase 2: Add Indic Parler-TTS (Best Hindi TTS)

**AI4Bharat's Indic Parler-TTS** is the best open-source TTS for Indian languages:
- 21 languages including Hindi, Marathi, Gujarati
- 69 unique speaker voices
- Emotion control (happy, sad, angry, etc.)
- Speed/pitch control

```python
from parler_tts import ParlerTTSForConditionalGeneration
from transformers import AutoTokenizer
import torch

device = "cuda:0"
model = ParlerTTSForConditionalGeneration.from_pretrained(
    "ai4bharat/indic-parler-tts"
).to(device)

# Generate with emotion and style control
description = "Divya speaks with a happy, energetic tone. Clear recording."
text = "à¤¨à¤®à¤¸à¥à¤¤à¥‡, à¤®à¥ˆà¤‚ à¤®à¤‚à¤—à¤µà¤¾à¤²à¥‡ à¤¹à¥‚à¤‚à¥¤ à¤†à¤œ à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥€ à¤•à¥ˆà¤¸à¥‡ à¤®à¤¦à¤¦ à¤•à¤° à¤¸à¤•à¤¤à¥€ à¤¹à¥‚à¤‚?"

audio = model.generate(description=description, prompt=text)
```

**Available Hindi Voices:**
| Voice | Style |
|-------|-------|
| Rohit | Male, recommended |
| Divya | Female, recommended |
| Aman | Male |
| Rani | Female |

### Phase 3: Implement True Real-time (Pipecat)

For "live talking" with interruption support, use **Pipecat**:

```python
# Install pipecat
pip install pipecat-ai[deepgram,elevenlabs,silero]

# Pipeline setup
from pipecat.pipeline import Pipeline
from pipecat.services.deepgram import DeepgramSTTService
from pipecat.services.elevenlabs import ElevenLabsTTSService
from pipecat.transports.network.websocket import WebsocketServerTransport

pipeline = Pipeline([
    WebsocketServerTransport(port=7100),
    DeepgramSTTService(api_key="..."),  # Real-time ASR
    YourLLMProcessor(),                   # Your Mangwale AI
    ElevenLabsTTSService(api_key="..."), # Real-time TTS
])
```

**Pipecat Benefits:**
- âœ… Sub-300ms total latency
- âœ… Interruption handling (barge-in)
- âœ… Built-in VAD with Silero
- âœ… Works with all your providers
- âœ… WebRTC support for lowest latency

## ğŸ“Š HuggingFace Datasets for Better Hindi

### For ASR Fine-tuning:
| Dataset | Hours | Languages | Use For |
|---------|-------|-----------|---------|
| ai4bharat/Rasa | 995K samples | 9 Indian | ASR training |
| ai4bharat/Rural_Women_ASR | 64K samples | Hindi, Bhojpuri | Rural accent |
| google/fleurs | 12hrs/lang | 102 langs | Multi-lang ASR |

### For TTS Training:
| Dataset | Description | Quality |
|---------|-------------|---------|
| ai4b-hf/GLOBE-annotated | 535hrs, 18 langs | â˜…â˜…â˜…â˜…â˜… |
| IndicTTS | 382hrs, 12 langs | â˜…â˜…â˜…â˜…â˜… |
| LIMMITS | 568hrs, 7 langs | â˜…â˜…â˜…â˜…â˜† |

### Quick Fine-tune Script:
```python
# Fine-tune Whisper on Hindi data
from datasets import load_dataset
from transformers import WhisperForConditionalGeneration, WhisperProcessor

# Load Hindi data
dataset = load_dataset("ai4bharat/Rasa", "hi", split="train")

# Load model
model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-large-v3")
processor = WhisperProcessor.from_pretrained("openai/whisper-large-v3")

# Fine-tune for Hindi accent recognition
# ... training code ...
```

## ğŸ’° Cost Analysis (1000 minutes/month)

| Strategy | ASR Cost | TTS Cost | Latency | Quality |
|----------|----------|----------|---------|---------|
| **Current (Local Only)** | $0 | $0 | ~5s | â˜…â˜…â˜…â˜…â˜† |
| **Hybrid (Local + Cloud)** | ~$4 | ~$15 | ~2s | â˜…â˜…â˜…â˜…â˜… |
| **Cloud Priority** | ~$8 | ~$30 | ~0.5s | â˜…â˜…â˜…â˜…â˜… |

## ğŸ”§ Immediate Actions

### 1. Test ElevenLabs (Already Working!)
```bash
curl -X POST http://192.168.0.151:7101/api/speak \
  -H "Content-Type: application/json" \
  -d '{"text": "à¤¨à¤®à¤¸à¥à¤¤à¥‡", "provider": "elevenlabs"}' -o test.mp3
```

### 2. Test Deepgram ASR
```bash
# Record 5 seconds of audio
arecord -d 5 -f S16_LE -r 16000 test.wav

# Transcribe with Deepgram
curl -X POST http://192.168.0.151:7101/api/transcribe \
  -H "Content-Type: application/json" \
  -d '{"audio": "'$(base64 -w0 test.wav)'", "language": "hi", "provider": "deepgram"}'
```

### 3. Check Provider Health
```bash
curl http://192.168.0.151:7101/api/providers/health | jq .
```

### 4. Monitor GPU Usage
```bash
ssh mercury 'watch -n 1 nvidia-smi'
```

## ğŸ“ˆ Performance Targets

| Metric | Current | Target | How |
|--------|---------|--------|-----|
| ASR Latency | ~2-3s | <500ms | Faster-Whisper Turbo |
| TTS Latency | ~3-5s | <200ms | ElevenLabs Flash / Indic-Parler |
| Total Round-trip | ~8-10s | <1s | Pipecat pipeline |
| Hindi Accuracy | ~90% | >95% | Fine-tuned model |

## ğŸ¯ Recommended Roadmap

### Week 1: Quick Wins
- [x] Add Deepgram API key
- [x] Add ElevenLabs API key
- [ ] Test cloud fallbacks
- [ ] Update ASR to Faster-Whisper

### Week 2: Optimization
- [ ] Add Indic Parler-TTS as local option
- [ ] Implement Silero VAD properly
- [ ] Add streaming TTS (chunk-by-chunk)

### Week 3: Real-time
- [ ] Evaluate Pipecat framework
- [ ] Add interruption handling
- [ ] Implement WebRTC for lower latency

### Week 4: Production
- [ ] Load testing
- [ ] Monitoring and alerting
- [ ] Documentation for team

---

**Your system is now ready with cloud fallbacks!** ğŸ‰

The local services are free and preserve privacy, while Deepgram and ElevenLabs provide fast fallbacks when needed.
